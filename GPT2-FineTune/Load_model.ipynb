{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOsDsLoq6H6LB4PlERgebtP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Load model"],"metadata":{"id":"StCjGY-VOo30"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zrLO1Kw_8-Kw"},"outputs":[],"source":["from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","import torch\n","# Load the fine-tuned model\n","model = GPT2LMHeadModel.from_pretrained(\"/content/drive/MyDrive/GPT2-finetune/Model\")\n","tokenizer = GPT2Tokenizer.from_pretrained(\"/content/drive/MyDrive/GPT2-finetune/Model\")\n"]},{"cell_type":"code","source":["# Generate some text\n","input_text = \"In a shocking finding, scientist discovered\"\n","\n","input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n","\n","\n","# Create an attention mask\n","attention_mask = torch.ones(input_ids.shape, dtype=torch.long)\n","\n","output = model.generate(input_ids,\n","                        max_length=50,\n","                         min_length=25,\n","                        do_sample=True,\n","                        attention_mask=attention_mask,\n","                        pad_token_id=tokenizer.eos_token_id,\n","                        temperature=1,\n","                        top_p=0.95,\n","                        top_k=10)\n","\n","generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","print(generated_text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Cd0YO0K1Gh9","executionInfo":{"status":"ok","timestamp":1696031717048,"user_tz":-180,"elapsed":1549,"user":{"displayName":"Ahmed Hany","userId":"11066611178035959836"}},"outputId":"2a44fa4f-fc81-48e0-d34c-193b2fc06823"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["In a shocking finding, scientist discovered a new species of human,rological monster that could cause the death of the gods.\n"]}]},{"cell_type":"code","source":["# Generate some text\n","input_text = \"In a shocking finding, scientist discovered\"\n","\n","input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n","\n","\n","# Create an attention mask\n","attention_mask = torch.ones(input_ids.shape, dtype=torch.long)\n","\n","output = model.generate(input_ids,\n","                        max_length=50,\n","                         min_length=25,\n","                        do_sample=True,\n","                        attention_mask=attention_mask,\n","                        pad_token_id=tokenizer.eos_token_id,\n","                        temperature=1,\n","                        top_p=0.95,\n","                        top_k=10)\n","\n","generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","print(generated_text)\n"],"metadata":{"id":"UEc_9m1a2UeU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696031847697,"user_tz":-180,"elapsed":3185,"user":{"displayName":"Ahmed Hany","userId":"11066611178035959836"}},"outputId":"5b80e233-5d3e-450e-c2b3-64094c27b24e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["In a shocking finding, scientist discovered the first known form of 'bastard' in the world. His name was Sir William\n"]}]},{"cell_type":"code","source":["# Generate some text\n","input_text = \"the girl was\"\n","\n","input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n","\n","\n","# Create an attention mask\n","attention_mask = torch.ones(input_ids.shape, dtype=torch.long)\n","\n","output = model.generate(input_ids,\n","                        max_length=50,\n","                         min_length=25,\n","                        do_sample=True,\n","                        attention_mask=attention_mask,\n","                        pad_token_id=tokenizer.eos_token_id,\n","                        temperature=1,\n","                        top_p=0.95,\n","                        top_k=10)\n","\n","generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","print(generated_text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mp8JsXucYCXX","executionInfo":{"status":"ok","timestamp":1696031866697,"user_tz":-180,"elapsed":2568,"user":{"displayName":"Ahmed Hany","userId":"11066611178035959836"}},"outputId":"d43ca35f-7ae4-4c3c-8393-d415fed129c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["the girl was. The prince, who, after a great deal of trouble, and the King's death, is not yet dead,\n"]}]},{"cell_type":"code","source":["# Generate some text\n","input_text = \"The war was\"\n","\n","input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n","\n","\n","# Create an attention mask\n","attention_mask = torch.ones(input_ids.shape, dtype=torch.long)\n","\n","output = model.generate(input_ids,\n","                        max_length=50,\n","                         min_length=40,\n","                        do_sample=True,\n","                        attention_mask=attention_mask,\n","                        pad_token_id=tokenizer.eos_token_id,\n","                        temperature=1.5,\n","                        top_p=0.95,\n","                        top_k=10)\n","\n","generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","print(generated_text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x-HGLAndYHNY","executionInfo":{"status":"ok","timestamp":1696032051052,"user_tz":-180,"elapsed":2822,"user":{"displayName":"Ahmed Hany","userId":"11066611178035959836"}},"outputId":"0834ffd8-6227-4d67-eb9d-6f2a06bf093b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The war was waged by the people of Syria, but they were not so strong in their faith. And they were so in a state, that they should not come\n","\n","To Rome, but \n"]}]},{"cell_type":"code","source":["# Generate some text\n","input_text = \"In a shocking finding,scientist discovered\"\n","\n","input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n","\n","\n","# Create an attention mask\n","attention_mask = torch.ones(input_ids.shape, dtype=torch.long)\n","\n","output = model.generate(input_ids,\n","                        max_length=100,\n","                         min_length=70,\n","                        do_sample=True,\n","                        attention_mask=attention_mask,\n","                        pad_token_id=tokenizer.eos_token_id,\n","                        temperature=2.0,\n","                        #top_p=0.95,\n","                        #top_k=50\n","                        )\n","\n","generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","print(generated_text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4vJkeTBJcFm6","executionInfo":{"status":"ok","timestamp":1696033407426,"user_tz":-180,"elapsed":3919,"user":{"displayName":"Ahmed Hany","userId":"11066611178035959836"}},"outputId":"ef9f6642-48fb-4ae9-cba8-603971a23cba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["In a shocking finding, scientist discovered some bizarre chemical substance on the floor and asked him for some news - his answers proved no. He found 'this chemical odour', the label by which  of life\n","Elvio Di Giavallaro was named in 1884\n","Trigging to an act and his love for  The New Yorker\n"]}]},{"cell_type":"markdown","source":["#Upload to Hugging face"],"metadata":{"id":"XSOcMEkURSVK"}},{"cell_type":"code","source":["!huggingface-cli login"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KUUJNU91RRw9","executionInfo":{"status":"ok","timestamp":1696097314781,"user_tz":-180,"elapsed":28979,"user":{"displayName":"Ahmed Hany","userId":"11066611178035959836"}},"outputId":"6604ce8e-5af4-476d-a721-bd2caf0d6b3a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","    \n","    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","Token: \n","Add token as git credential? (Y/n) y\n","Token is valid (permission: write).\n","\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n","You might have to re-authenticate when pushing to the Hugging Face Hub.\n","Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n","\n","git config --global credential.helper store\n","\n","Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n","Token has not been saved to git credential helper.\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}]},{"cell_type":"code","source":["!huggingface-cli repo create GPT2-SMALL_GENERATE"],"metadata":{"id":"xb_7IRGHeyDC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696097424486,"user_tz":-180,"elapsed":10704,"user":{"displayName":"Ahmed Hany","userId":"11066611178035959836"}},"outputId":"295aa47d-7709-4281-a2d5-fea0b750914b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[90mgit version 2.34.1\u001b[0m\n","\u001b[90mgit-lfs/3.0.2 (GitHub; linux amd64; go 1.18.1)\u001b[0m\n","\n","You are about to create \u001b[1mAhmedhany216/GPT2-SMALL_GENERATE\u001b[0m\n","Proceed? [Y/n] Y\n","\n","Your repo now lives at:\n","  \u001b[1mhttps://huggingface.co/Ahmedhany216/GPT2-SMALL_GENERATE\u001b[0m\n","\n","You can clone it locally with the command below, and commit/push as usual.\n","\n","  git clone https://huggingface.co/Ahmedhany216/GPT2-SMALL_GENERATE\n","\n"]}]},{"cell_type":"code","source":["!git clone https://huggingface.co/Ahmedhany216/GPT2-SMALL_GENERATE"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MLQj3KiGSKkK","executionInfo":{"status":"ok","timestamp":1696097462293,"user_tz":-180,"elapsed":696,"user":{"displayName":"Ahmed Hany","userId":"11066611178035959836"}},"outputId":"b1106ecb-d200-4d0f-a394-f0f60642991e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'GPT2-SMALL_GENERATE'...\n","remote: Enumerating objects: 3, done.\u001b[K\n","remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 3\u001b[K\n","Unpacking objects:  33% (1/3)\rUnpacking objects:  66% (2/3)\rUnpacking objects: 100% (3/3)\rUnpacking objects: 100% (3/3), 417 bytes | 417.00 KiB/s, done.\n"]}]},{"cell_type":"code","source":["!cp -r /content/drive/MyDrive/GPT2-finetune/Model/* /content/GPT2-SMALL_GENERATE/\n"],"metadata":{"id":"jO65YETbSWPQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/GPT2-SMALL_GENERATE/\n","!git add .\n","!git commit -m \"Initial commit with fine-tuned model.\"\n","!git push\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fqZp5dclSfmU","executionInfo":{"status":"ok","timestamp":1696097668883,"user_tz":-180,"elapsed":2733,"user":{"displayName":"Ahmed Hany","userId":"11066611178035959836"}},"outputId":"d9b7d753-d15e-48c7-8de6-d807ae71984b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/GPT2-SMALL_GENERATE\n","Author identity unknown\n","\n","*** Please tell me who you are.\n","\n","Run\n","\n","  git config --global user.email \"you@example.com\"\n","  git config --global user.name \"Your Name\"\n","\n","to set your account's default identity.\n","Omit --global to set the identity only in this repository.\n","\n","fatal: unable to auto-detect email address (got 'root@1dd1f31ac950.(none)')\n","fatal: could not read Username for 'https://huggingface.co': No such device or address\n"]}]},{"cell_type":"code","source":["!git config --global user.email \"Ahmedhany216216@gmail.com\"\n","!git config --global user.name \"Ahmedhany216\""],"metadata":{"id":"ahXlvRuHTIL0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/GPT2-SMALL_GENERATE/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BVA4cfe5Vrbk","executionInfo":{"status":"ok","timestamp":1696098536217,"user_tz":-180,"elapsed":297,"user":{"displayName":"Ahmed Hany","userId":"11066611178035959836"}},"outputId":"92c3c83d-eb56-4403-e7bb-7b00014842e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/GPT2-SMALL_GENERATE\n"]}]},{"cell_type":"code","source":["!git remote rm origin\n","!git remote add origin https://huggingface.co/Ahmedhany216/GPT2-SMALL_GENERATE.git"],"metadata":{"id":"qGufAVhBWcgv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git remote set-url origin https://Ahmedhany216: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@huggingface.co/Ahmedhany216/GPT2-SMALL_GENERATE.git"],"metadata":{"id":"G6r9XxiDWtMo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git push -u origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rNJ_58fLXB-c","executionInfo":{"status":"ok","timestamp":1696098707794,"user_tz":-180,"elapsed":2750,"user":{"displayName":"Ahmed Hany","userId":"11066611178035959836"}},"outputId":"a4c0f809-4b53-4a4d-aa2b-dcdb55e2bc0a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enumerating objects: 10, done.\n","Counting objects: 100% (10/10), done.\n","Delta compression using up to 2 threads\n","Compressing objects: 100% (9/9), done.\n","Writing objects: 100% (9/9), 521.58 KiB | 3.16 MiB/s, done.\n","Total 9 (delta 0), reused 0 (delta 0), pack-reused 0\n","To https://huggingface.co/Ahmedhany216/GPT2-SMALL_GENERATE.git\n","   f7acb42..0530d58  main -> main\n","Branch 'main' set up to track remote branch 'main' from 'origin'.\n"]}]},{"cell_type":"code","source":["from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","\n","# Specify the model name or path\n","model_name_or_path = \"Ahmedhany216/GPT2-SMALL_GENERATE\"\n","\n","# Load the tokenizer\n","tokenizer = GPT2Tokenizer.from_pretrained(model_name_or_path)\n","\n","# Load the model\n","model = GPT2LMHeadModel.from_pretrained(model_name_or_path)"],"metadata":{"id":"NEZgL6mTXFyv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generate some text\n","input_text = \"the king was\"\n","\n","input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n","\n","\n","# Create an attention mask\n","attention_mask = torch.ones(input_ids.shape, dtype=torch.long)\n","\n","output = model.generate(input_ids,\n","                        max_length=30,\n","                         min_length=20,\n","                        do_sample=True,\n","                        attention_mask=attention_mask,\n","                        pad_token_id=tokenizer.eos_token_id,\n","                        temperature=1,\n","                        top_p=0.95,\n","                        top_k=50)\n","\n","generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","print(generated_text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"on9uL-76ZPxW","executionInfo":{"status":"ok","timestamp":1696099318463,"user_tz":-180,"elapsed":2369,"user":{"displayName":"Ahmed Hany","userId":"11066611178035959836"}},"outputId":"47456aac-1f49-4ae8-b718-70e0446ab77f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["the king was pleased that his countrymen, in their hands and in their pockets, were found by these\n"]}]},{"cell_type":"code","source":["model.config.save_pretrained(\"/content/drive/MyDrive/GPT2-finetune/Model\")"],"metadata":{"id":"-M5c0DqZbUou"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LaYaXQsIglKF"},"execution_count":null,"outputs":[]}]}