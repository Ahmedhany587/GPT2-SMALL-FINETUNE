{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["Si_cxthK3iik","dHL5gI2x68lH"],"authorship_tag":"ABX9TyM7jN9gRtdUPhOvzPpNK2vh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Si_cxthK3iik"},"source":["#GPT2-FINE TUNNING"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TcCIO2cE2Ns6"},"outputs":[],"source":["from datasets import load_from_disk\n","\n","# Load previously tokenized datasets from the specified directory\n","tokenized_datasets = load_from_disk(f\"{base_dir}/tokenized_datasets\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":65,"status":"ok","timestamp":1696015666155,"user":{"displayName":"Ahmed Hany","userId":"11066611178035959836"},"user_tz":-120},"id":"6uP5F2qR8ang","outputId":"33c603bb-6106-45cc-a6c7-f6f26b3725aa"},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['text', 'input_ids', 'attention_mask'],\n","    num_rows: 99357\n","})"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# Display the tokenized training dataset\n","tokenized_datasets['train']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54,"status":"ok","timestamp":1696015666157,"user":{"displayName":"Ahmed Hany","userId":"11066611178035959836"},"user_tz":-120},"id":"nWLwPX8J8hld","outputId":"6c1fb73e-51b1-4d68-d99c-238dd9436cc2"},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['text', 'input_ids', 'attention_mask'],\n","    num_rows: 24840\n","})"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# Display the tokenized validation dataset\n","tokenized_datasets['validation']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-aU-cb_D2YXg"},"outputs":[],"source":["# Importing the 'accelerate' library for streamlined hardware acceleration\n","import accelerate\n","import transformers\n","# Importing necessary class for setting up training arguments\n","from transformers import TrainingArguments\n","from transformers import DataCollatorForLanguageModeling\n","\n","# Setting up training arguments for the training session\n","training_args = TrainingArguments(\n","    per_device_train_batch_size=4,   # Batch size for training\n","    per_device_eval_batch_size=4,    # Batch size for evaluation\n","    num_train_epochs=3,              # Total number of training epochs\n","    gradient_accumulation_steps=4,   # Number of updates steps to accumulate before performing a backward/update pass\n","    logging_steps=100,               # Log metrics every 100 steps\n","    fp16=True,\n","    evaluation_strategy=\"steps\",     # Evaluate the model every 'eval_steps'\n","    eval_steps=500,                  # Evaluate the model every 500 steps\n","    learning_rate=5e-5,              # Learning rate\n","    weight_decay=0.01,               # Weight decay\n","    save_steps=500,                  # Save the model every 500 steps\n","    save_total_limit=3,              # Keep only the last 3 models\n","    logging_dir=f'{base_dir}/logs',  # Directory for storing logs\n","    output_dir=f'{base_dir}/results' # Directory for storing results and model checkpoints\n",")\n","data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y_iOaEyc6k95"},"outputs":[],"source":["# Import necessary modules from the transformers library\n","from transformers import Trainer\n","import torch\n","\n","# Define a custom collation function to handle batching of data\n","def collate_batch(data):\n","    # Stacking input_ids from the tokenized data\n","    input_ids = torch.stack([torch.tensor(item['input_ids']) for item in data])\n","\n","    # Stacking attention masks from the tokenized data\n","    attention_mask = torch.stack([torch.tensor(item['attention_mask']) for item in data])\n","\n","    # Using input_ids as labels (relevant for tasks like masked language modeling)\n","    labels = torch.stack([torch.tensor(item['input_ids']) for item in data])\n","\n","    # Return a dictionary with keys corresponding to model input names\n","    return {\n","        'input_ids': input_ids,\n","        'attention_mask': attention_mask,\n","        'labels': labels\n","    }\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":294},"executionInfo":{"elapsed":3023776,"status":"ok","timestamp":1696020125555,"user":{"displayName":"Ahmed Hany","userId":"11066611178035959836"},"user_tz":-120},"id":"Z2NV45RD6xeK","outputId":"a1f87d8a-5944-42fb-cb8d-79a44a5e0728"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='18630' max='18630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [18630/18630 50:21, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>18000</td>\n","      <td>0.104000</td>\n","      <td>0.104319</td>\n","    </tr>\n","    <tr>\n","      <td>18500</td>\n","      <td>0.105500</td>\n","      <td>0.104324</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=18630, training_loss=0.006397193667073437, metrics={'train_runtime': 3023.2438, 'train_samples_per_second': 98.593, 'train_steps_per_second': 6.162, 'total_flos': 7.815362055399014e+16, 'train_loss': 0.006397193667073437, 'epoch': 3.0})"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# Set up the Trainer with the model, training arguments, datasets, and the custom data collator\n","trainer = Trainer(\n","    model=model,                                        # Model to be trained\n","    args=training_args,                                 # Training arguments\n","    train_dataset=tokenized_datasets[\"train\"],          # Training dataset\n","    eval_dataset=tokenized_datasets[\"validation\"],      # Evaluation dataset\n","    data_collator=collate_batch                         # Custom function to form batches\n",")\n","model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n","\n","# Start the training process\n","trainer.train('/content/drive/MyDrive/GPT2-finetune/results/checkpoint-18500')"]},{"cell_type":"code","source":["import math\n","\n","# Given validation loss\n","validation_loss = 0.104324\n","\n","# Compute perplexity\n","perplexity = math.exp(validation_loss)\n","\n","print(\"Perplexity:\", perplexity)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yh1Zq23xRrtd","executionInfo":{"status":"ok","timestamp":1696030181420,"user_tz":-180,"elapsed":310,"user":{"displayName":"Ahmed Hany","userId":"11066611178035959836"}},"outputId":"7d4f8496-aec1-4a58-a192-6ffb1c290c5b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Perplexity: 1.1099600237099743\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uQTRwem15TEV"},"outputs":[],"source":["results = trainer.evaluate()"]},{"cell_type":"markdown","metadata":{"id":"dHL5gI2x68lH"},"source":["#Save Model"]},{"cell_type":"code","source":["model.save_pretrained(\"/content/drive/MyDrive/GPT2-finetune/Model\")\n","tokenizer.save_pretrained(\"/content/drive/MyDrive/GPT2-finetune/Model\")"],"metadata":{"id":"-L-5YnQp0f7x"},"execution_count":null,"outputs":[]}]}